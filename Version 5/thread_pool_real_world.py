import threading
import time
import psutil
import os
import math
import statistics
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from PIL import Image, ImageFilter, ImageEnhance
import requests
from bs4 import BeautifulSoup
from io import BytesIO
import tempfile
from typing import List, Tuple
from functools import partial

# =====================================================================
# WORKER WRAPPER (needed for ProcessPoolExecutor pickling)
# =====================================================================
def worker_wrapper(task_data):
    """
    Wrapper function that can be pickled for ProcessPoolExecutor
    task_data is a tuple of (func, args)
    """
    func, args = task_data
    return func(*args)

# =====================================================================
# DYNAMIC OPTIMAL POOL SIZE CALCULATOR
# =====================================================================
class OptimalPoolCalculator:
    """
    Calculates optimal thread/process pool sizes based on:
    - System CPU cores
    - Workload type (CPU-bound vs IO-bound)
    - Task characteristics
    """

    def __init__(self):
        self.cpu_cores = os.cpu_count() or 4

    def calculate(self, workload_type: str, task_intensity: str = "medium") -> dict:
        """
        Calculate optimal pool sizes for different approaches

        Args:
            workload_type: "cpu", "io", or "mixed"
            task_intensity: "light", "medium", "heavy"

        Returns:
            dict with recommended pool sizes for different executors
        """
        if workload_type == "cpu":
            # CPU-bound: Limited by GIL in threading, best with processes
            thread_pool = self.cpu_cores  # Threading won't help much due to GIL
            process_pool = self.cpu_cores  # One per core

        elif workload_type == "io":
            # IO-bound: Can use many threads since they're waiting, not computing
            if task_intensity == "light":
                thread_pool = self.cpu_cores * 8  # Very light I/O (fast responses)
            elif task_intensity == "heavy":
                thread_pool = self.cpu_cores * 2  # Heavy I/O (slow responses)
            else:
                thread_pool = self.cpu_cores * 4  # Medium I/O

            process_pool = None  # Processes add overhead for I/O tasks

        else:  # mixed
            thread_pool = self.cpu_cores * 2
            process_pool = self.cpu_cores

        return {
            "thread_pool": thread_pool,
            "process_pool": process_pool,
            "new_threads_recommended": False,  # Almost never optimal
            "reasoning": self._get_reasoning(workload_type, task_intensity)
        }

    def _get_reasoning(self, workload: str, intensity: str) -> str:
        """Provide explanation for the recommendation"""
        if workload == "cpu":
            return (f"CPU-bound on {self.cpu_cores} cores: Use ProcessPoolExecutor "
                   "to bypass GIL. ThreadPoolExecutor will be limited by GIL.")
        elif workload == "io":
            multiplier = {"light": 8, "medium": 4, "heavy": 2}[intensity]
            return (f"IO-bound ({intensity}): Use {self.cpu_cores * multiplier} threads. "
                   f"Threads can efficiently handle waiting for I/O operations.")
        else:
            return f"Mixed workload: Balance between {self.cpu_cores * 2} threads and {self.cpu_cores} processes."

# =====================================================================
# CPU-BOUND TASKS (Image Processing & Factorial)
# =====================================================================
def generate_test_image(size=(800, 600)):
    """Generate a colorful test image for processing"""
    from PIL import ImageDraw
    img = Image.new('RGB', size, color=(135, 206, 235))  # Sky blue background
    draw = ImageDraw.Draw(img)

    # Draw some shapes to make the image interesting
    # Sun
    draw.ellipse([650, 50, 750, 150], fill=(255, 255, 0))

    # Ground
    draw.rectangle([0, 400, 800, 600], fill=(34, 139, 34))

    # House
    draw.rectangle([200, 300, 400, 500], fill=(139, 69, 19))
    draw.polygon([(200, 300), (300, 200), (400, 300)], fill=(178, 34, 34))

    # Windows
    draw.rectangle([230, 350, 270, 400], fill=(173, 216, 230))
    draw.rectangle([330, 350, 370, 400], fill=(173, 216, 230))

    # Door
    draw.rectangle([280, 420, 320, 500], fill=(101, 67, 33))

    # Trees
    draw.rectangle([500, 380, 520, 500], fill=(101, 67, 33))
    draw.ellipse([460, 320, 560, 420], fill=(0, 100, 0))

    draw.rectangle([100, 380, 120, 500], fill=(101, 67, 33))
    draw.ellipse([60, 320, 160, 420], fill=(0, 128, 0))

    return img

def image_processing_task(image_data: bytes) -> bytes:
    """
    HEAVY CPU-intensive image processing:
    - Multiple Gaussian blurs (radius 10)
    - Contrast enhancement
    - Brightness adjustment
    - Color enhancement
    - Sharpness enhancement
    - Edge detection
    - Multiple smoothing passes
    - Detail enhancement
    """
    img = Image.open(BytesIO(image_data))

    # Apply multiple heavy filters (VERY CPU-intensive)
    # Round 1: Blur and enhance
    img = img.filter(ImageFilter.GaussianBlur(radius=10))
    img = img.filter(ImageFilter.GaussianBlur(radius=8))
    img = ImageEnhance.Contrast(img).enhance(1.8)
    img = ImageEnhance.Brightness(img).enhance(1.2)

    # Round 2: Color and sharpness
    img = ImageEnhance.Color(img).enhance(1.5)
    img = ImageEnhance.Sharpness(img).enhance(2.0)

    # Round 3: Edge detection and smoothing
    img = img.filter(ImageFilter.FIND_EDGES)
    img = img.filter(ImageFilter.SMOOTH_MORE)
    img = img.filter(ImageFilter.SMOOTH)

    # Round 4: Detail enhancement
    img = img.filter(ImageFilter.DETAIL)
    img = img.filter(ImageFilter.EDGE_ENHANCE)
    img = img.filter(ImageFilter.EDGE_ENHANCE_MORE)

    # Final blur
    img = img.filter(ImageFilter.GaussianBlur(radius=5))

    # Convert back to bytes
    output = BytesIO()
    img.save(output, format='PNG')
    return output.getvalue()

def factorial_task(n: int) -> int:
    """
    CPU-intensive: Calculate factorial iteratively
    Using iterative approach to avoid recursion limits
    """
    result = 1
    for i in range(2, n + 1):
        result *= i
    return result

# =====================================================================
# IO-BOUND TASKS (Web Crawling & Sleep)
# =====================================================================
def web_crawler_task(url: str, depth: int = 1) -> dict:
    """
    IO-bound web crawler for ipsantarem.pt
    Fetches page and extracts links

    Args:
        url: URL to crawl
        depth: How many levels deep to crawl (default: 1)

    Returns:
        dict with page info and links found
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Research Bot/1.0; Thread Pool Analysis)',
            'Accept': 'text/html,application/xhtml+xml',
        }

        # This is the I/O operation - waiting for network response
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()

        # Parse HTML (minimal CPU work)
        soup = BeautifulSoup(response.text, 'html.parser')

        # Extract information
        title = soup.title.string if soup.title else "No title"
        links = [a.get('href') for a in soup.find_all('a', href=True)][:10]

        return {
            'url': url,
            'status': response.status_code,
            'title': title,
            'links_found': len(links),
            'content_length': len(response.text)
        }
    except Exception as e:
        return {
            'url': url,
            'status': 'error',
            'error': str(e)
        }

def sleep_task(duration: float = 0.1) -> float:
    """
    Simple IO-bound task: sleep
    Simulates waiting for I/O operations
    """
    time.sleep(duration)
    return duration

# =====================================================================
# EXECUTION APPROACHES
# =====================================================================
def run_new_threads(num_tasks: int, func, *args):
    """Create a new thread for each task (NOT recommended)"""
    threads = []
    for _ in range(num_tasks):
        t = threading.Thread(target=func, args=args)
        threads.append(t)
        t.start()
    for t in threads:
        t.join()

def run_thread_pool(num_tasks: int, func, *args, max_workers=None):
    """Use ThreadPoolExecutor with optimal pool size"""
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Use list comprehension instead of lambda for better compatibility
        futures = [executor.submit(func, *args) for _ in range(num_tasks)]
        for future in futures:
            future.result()

def run_process_pool(num_tasks: int, func, *args, max_workers=None):
    """Use ProcessPoolExecutor for CPU-bound tasks"""
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        # Create list of task data tuples (func, args) for each task
        task_data = [(func, args) for _ in range(num_tasks)]
        list(executor.map(worker_wrapper, task_data))

# =====================================================================
# PERFORMANCE MEASUREMENT
# =====================================================================
def measure_performance(run_func, num_tasks: int, label: str, func, *args,
                       iterations: int = 3, **kwargs):
    """
    Measure performance with multiple iterations and statistics
    """
    process = psutil.Process(os.getpid())
    results = []

    print(f"\n{'='*70}")
    print(f"Testing: {label}")
    print(f"Tasks: {num_tasks} | Iterations: {iterations}")
    print(f"{'='*70}")

    for i in range(iterations):
        time.sleep(0.3)  # Cool-down between runs

        mem_before = process.memory_info().rss / (1024*1024)
        threads_before = threading.active_count()

        start = time.perf_counter()
        try:
            run_func(num_tasks, func, *args, **kwargs)
            elapsed = time.perf_counter() - start
        except Exception as e:
            print(f"  ‚ùå Run {i+1} failed: {e}")
            continue

        mem_after = process.memory_info().rss / (1024*1024)
        threads_after = threading.active_count()
        cpu_percent = psutil.cpu_percent(interval=0.1)

        throughput = num_tasks / elapsed if elapsed > 0 else 0
        mem_delta = mem_after - mem_before

        results.append({
            'iteration': i + 1,
            'time': elapsed,
            'throughput': throughput,
            'memory': mem_delta,
            'cpu': cpu_percent
        })

        print(f"  Run {i+1}: {elapsed:.3f}s | {throughput:.2f} tasks/s | "
              f"Mem: {mem_delta:+.2f}MB | CPU: {cpu_percent:.1f}%")

    if not results:
        print("  ‚ö†Ô∏è All iterations failed!")
        return None

    # Calculate statistics
    times = [r['time'] for r in results]
    throughputs = [r['throughput'] for r in results]

    avg_time = statistics.mean(times)
    std_time = statistics.stdev(times) if len(times) > 1 else 0
    avg_throughput = statistics.mean(throughputs)

    print(f"\n  üìä Average: {avg_time:.3f}s ¬± {std_time:.3f}s")
    print(f"  üìà Throughput: {avg_throughput:.2f} tasks/s")

    return {
        'label': label,
        'avg_time': avg_time,
        'std_time': std_time,
        'avg_throughput': avg_throughput
    }

# =====================================================================
# OPTIMAL POOL SIZE TESTING
# =====================================================================
def find_optimal_pool_size(num_tasks: int, func, args, workload_type: str,
                          test_sizes: List[int] = None):
    """
    Test different pool sizes to empirically find the optimal size
    """
    print(f"\n{'#'*70}")
    print(f"FINDING OPTIMAL POOL SIZE - {workload_type.upper()}")
    print(f"{'#'*70}")

    if test_sizes is None:
        cores = os.cpu_count()
        if workload_type == "cpu":
            test_sizes = [cores // 2, cores, cores * 2] if cores > 1 else [1, 2, 4]
        else:  # IO
            test_sizes = [cores, cores * 2, cores * 4, cores * 8]

    results = {}
    for pool_size in test_sizes:
        label = f"ThreadPool (size={pool_size})"
        result = measure_performance(
            run_thread_pool, num_tasks, label, func, *args,
            max_workers=pool_size, iterations=2
        )
        if result:
            results[pool_size] = result['avg_time']

            # Show comparison to baseline
            if len(results) > 1:
                baseline = list(results.values())[0]
                speedup = baseline / result['avg_time']
                print(f"    ‚Üí Speedup vs size={test_sizes[0]}: {speedup:.2f}x")

    if not results:
        print("  ‚ö†Ô∏è No successful tests!")
        return None, {}

    # Find optimal
    optimal_size = min(results.items(), key=lambda x: x[1])
    print(f"\n  ‚úÖ OPTIMAL POOL SIZE: {optimal_size[0]} (Time: {optimal_size[1]:.3f}s)")

    return optimal_size[0], results

# =====================================================================
# COMPREHENSIVE TEST SUITE
# =====================================================================
def run_comprehensive_tests():
    """
    Run comprehensive performance comparison
    """
    calculator = OptimalPoolCalculator()
    cores = calculator.cpu_cores

    print(f"\n{'='*70}")
    print(f"THREAD POOL vs NEW THREADS - COMPREHENSIVE ANALYSIS")
    print(f"{'='*70}")
    print(f"System: {cores} CPU cores detected")
    print(f"Testing: Image Processing, Factorial, Web Crawling, Sleep")

    # Store all results for final summary
    all_results = {}

    # Prepare test data
    test_image = generate_test_image((800, 600))  # Larger image
    img_bytes = BytesIO()
    test_image.save(img_bytes, format='PNG')
    image_data = img_bytes.getvalue()

    print(f"\nüì∑ Test Image: 800x600 pixels, {len(image_data)/1024:.1f} KB")

    # Save original image
    test_image.save("original_test_image.png")
    print(f"   ‚úÖ Original image saved: original_test_image.png")

    # Process one image to show the result
    print(f"   üîÑ Processing sample image to show results...")
    processed_bytes = image_processing_task(image_data)
    processed_img = Image.open(BytesIO(processed_bytes))
    processed_img.save("processed_test_image.png")
    print(f"   ‚úÖ Processed image saved: processed_test_image.png")
    print(f"   üìä Applied 14 filters: Gaussian blur (3x), contrast, brightness,")
    print(f"      color, sharpness, edge detection, smoothing (2x), detail, edge enhance (2x)")

    # ---------------------------------------------------------------
    # TEST 1: CPU-BOUND - IMAGE PROCESSING
    # ---------------------------------------------------------------
    print(f"\n\n{'#'*70}")
    print(f"TEST 1: CPU-BOUND - HEAVY IMAGE PROCESSING")
    print(f"{'#'*70}")

    recommendations = calculator.calculate("cpu", "heavy")
    print(f"\nüí° Recommendations: {recommendations['reasoning']}")

    num_images = 30  # More images for heavier test

    # New threads (not recommended)
    result_img_new = measure_performance(
        run_new_threads, num_images,
        "New Threads - Image Processing",
        image_processing_task, image_data,
        iterations=2
    )
    all_results['img_new_threads'] = result_img_new

    # Thread pool (limited by GIL)
    result_img_thread = measure_performance(
        run_thread_pool, num_images,
        f"ThreadPool (size={recommendations['thread_pool']}) - Image Processing",
        image_processing_task, image_data,
        max_workers=recommendations['thread_pool'],
        iterations=2
    )
    all_results['img_thread_pool'] = result_img_thread

    # Process pool (BEST for CPU-bound)
    print("\nüîÑ Testing ProcessPoolExecutor (this may take a moment)...")
    result_img_process = measure_performance(
        run_process_pool, num_images,
        f"ProcessPool (size={recommendations['process_pool']}) - Image Processing",
        image_processing_task, image_data,
        max_workers=recommendations['process_pool'],
        iterations=2
    )
    all_results['img_process_pool'] = result_img_process

    # ---------------------------------------------------------------
    # TEST 2: CPU-BOUND - FACTORIAL CALCULATION
    # ---------------------------------------------------------------
    print(f"\n\n{'#'*70}")
    print(f"TEST 2: CPU-BOUND - FACTORIAL CALCULATION")
    print(f"{'#'*70}")

    num_factorials = 50
    factorial_n = 50000

    result_fact_new = measure_performance(
        run_new_threads, num_factorials,
        "New Threads - Factorial",
        factorial_task, factorial_n,
        iterations=2
    )
    all_results['fact_new_threads'] = result_fact_new

    result_fact_thread = measure_performance(
        run_thread_pool, num_factorials,
        f"ThreadPool (size={recommendations['thread_pool']}) - Factorial",
        factorial_task, factorial_n,
        max_workers=recommendations['thread_pool'],
        iterations=2
    )
    all_results['fact_thread_pool'] = result_fact_thread

    print("\nüîÑ Testing ProcessPoolExecutor (this may take a moment)...")
    result_fact_process = measure_performance(
        run_process_pool, num_factorials,
        f"ProcessPool (size={recommendations['process_pool']}) - Factorial",
        factorial_task, factorial_n,
        max_workers=recommendations['process_pool'],
        iterations=2
    )
    all_results['fact_process_pool'] = result_fact_process

    # ---------------------------------------------------------------
    # TEST 3: IO-BOUND - WEB CRAWLING
    # ---------------------------------------------------------------
    print(f"\n\n{'#'*70}")
    print(f"TEST 3: IO-BOUND - WEB CRAWLING (ipsantarem.pt)")
    print(f"{'#'*70}")

    recommendations_io = calculator.calculate("io", "medium")
    print(f"\nüí° Recommendations: {recommendations_io['reasoning']}")

    # Test URLs from ipsantarem.pt
    test_url = "https://www.ipsantarem.pt/"

    num_requests = 15

    print("\n‚ö†Ô∏è  Note: Respecting rate limits with delays between batches")

    # New threads
    result_web_new = measure_performance(
        run_new_threads, num_requests,
        "New Threads - Web Crawling",
        web_crawler_task, test_url,
        iterations=1
    )
    all_results['web_new_threads'] = result_web_new
    time.sleep(0.5)  # Respect rate limits

    # Thread pool with optimal size
    result_web_thread = measure_performance(
        run_thread_pool, num_requests,
        f"ThreadPool (size={recommendations_io['thread_pool']}) - Web Crawling",
        web_crawler_task, test_url,
        max_workers=recommendations_io['thread_pool'],
        iterations=1
    )
    all_results['web_thread_pool'] = result_web_thread
    time.sleep(0.5)

    # Find empirically optimal size for this specific workload
    print("\nüîç Finding empirical optimal pool size...")
    optimal_io, web_pool_results = find_optimal_pool_size(
        num_requests, web_crawler_task, (test_url,), "io"
    )
    all_results['web_optimal_size'] = optimal_io
    all_results['web_pool_sizes'] = web_pool_results

    # ---------------------------------------------------------------
    # TEST 4: IO-BOUND - SLEEP TASKS
    # ---------------------------------------------------------------
    print(f"\n\n{'#'*70}")
    print(f"TEST 4: IO-BOUND - SLEEP TASKS")
    print(f"{'#'*70}")

    num_sleeps = 100
    sleep_duration = 0.05

    recommendations_io_light = calculator.calculate("io", "light")
    print(f"\nüí° Recommendations: {recommendations_io_light['reasoning']}")

    result_sleep_new = measure_performance(
        run_new_threads, num_sleeps,
        "New Threads - Sleep",
        sleep_task, sleep_duration,
        iterations=2
    )
    all_results['sleep_new_threads'] = result_sleep_new

    result_sleep_thread = measure_performance(
        run_thread_pool, num_sleeps,
        f"ThreadPool (size={recommendations_io_light['thread_pool']}) - Sleep",
        sleep_task, sleep_duration,
        max_workers=recommendations_io_light['thread_pool'],
        iterations=2
    )
    all_results['sleep_thread_pool'] = result_sleep_thread

    # Find optimal for light I/O
    print("\nüîç Finding empirical optimal pool size for light I/O...")
    optimal_sleep, sleep_pool_results = find_optimal_pool_size(
        num_sleeps, sleep_task, (sleep_duration,), "io",
        test_sizes=[cores*4, cores*8, cores*16, cores*32]
    )
    all_results['sleep_optimal_size'] = optimal_sleep
    all_results['sleep_pool_sizes'] = sleep_pool_results

    # Return results for final summary
    return all_results

# =====================================================================
# MAIN EXECUTION
# =====================================================================
if __name__ == "__main__":
    print("\n" + "="*70)
    print("THREAD POOL PERFORMANCE ANALYSIS")
    print("Real-World Tasks: Image Processing, Factorial, Web Crawling")
    print("="*70)

    # Show system info and recommendations
    calculator = OptimalPoolCalculator()
    print(f"\nüñ•Ô∏è  System: {calculator.cpu_cores} CPU cores")
    print("\nüìã Optimal Pool Size Recommendations:")
    print("-" * 70)

    for workload in ["cpu", "io"]:
        for intensity in ["light", "medium", "heavy"]:
            if workload == "cpu" and intensity != "heavy":
                continue  # Only show heavy for CPU
            rec = calculator.calculate(workload, intensity)
            print(f"\n{workload.upper()}-bound ({intensity}):")
            print(f"  Thread Pool: {rec['thread_pool']}")
            if rec['process_pool']:
                print(f"  Process Pool: {rec['process_pool']}")
            print(f"  Reasoning: {rec['reasoning']}")

    print("\n" + "="*70)
    input("\nPress Enter to start comprehensive tests...")

    try:
        results = run_comprehensive_tests()

        print("\n" + "="*70)
        print("‚úÖ TESTING COMPLETE - DETAILED RESULTS")
        print("="*70)

        # ============================================================
        # DETAILED DATA ANALYSIS
        # ============================================================

        print("\n" + "="*70)
        print("üìä COMPREHENSIVE DATA SUMMARY")
        print("="*70)

        # CPU-BOUND TASKS: IMAGE PROCESSING
        print("\n" + "-"*70)
        print("1Ô∏è‚É£  CPU-BOUND: IMAGE PROCESSING (30 tasks, 800x600 px)")
        print("-"*70)
        if results.get('img_new_threads') and results.get('img_thread_pool') and results.get('img_process_pool'):
            img_new = results['img_new_threads']['avg_time']
            img_thread = results['img_thread_pool']['avg_time']
            img_process = results['img_process_pool']['avg_time']

            print(f"  New Threads:          {img_new:>8.3f}s  ({results['img_new_threads']['avg_throughput']:.2f} tasks/s)")
            print(f"  ThreadPool (24):      {img_thread:>8.3f}s  ({results['img_thread_pool']['avg_throughput']:.2f} tasks/s)")
            print(f"  ProcessPool (24):     {img_process:>8.3f}s  ({results['img_process_pool']['avg_throughput']:.2f} tasks/s)")
            print(f"\n  ‚ö° ProcessPool Speedup vs New Threads:   {img_new/img_process:.2f}x FASTER")
            print(f"  ‚ö° ProcessPool Speedup vs ThreadPool:    {img_thread/img_process:.2f}x FASTER")

            if img_process < img_new and img_process < img_thread:
                print(f"  ‚úÖ WINNER: ProcessPool (bypasses GIL for CPU-intensive work)")
            elif img_thread < img_process:
                print(f"  ‚ö†Ô∏è  ThreadPool faster (task overhead > computation time)")

        # CPU-BOUND TASKS: FACTORIAL
        print("\n" + "-"*70)
        print("2Ô∏è‚É£  CPU-BOUND: FACTORIAL CALCULATION (50 tasks, 50,000!)")
        print("-"*70)
        if results.get('fact_new_threads') and results.get('fact_thread_pool') and results.get('fact_process_pool'):
            fact_new = results['fact_new_threads']['avg_time']
            fact_thread = results['fact_thread_pool']['avg_time']
            fact_process = results['fact_process_pool']['avg_time']

            print(f"  New Threads:          {fact_new:>8.3f}s  ({results['fact_new_threads']['avg_throughput']:.2f} tasks/s)")
            print(f"  ThreadPool (24):      {fact_thread:>8.3f}s  ({results['fact_thread_pool']['avg_throughput']:.2f} tasks/s)")
            print(f"  ProcessPool (24):     {fact_process:>8.3f}s  ({results['fact_process_pool']['avg_throughput']:.2f} tasks/s)")
            print(f"\n  ‚ö° ProcessPool Speedup vs New Threads:   {fact_new/fact_process:.2f}x FASTER")
            print(f"  ‚ö° ProcessPool Speedup vs ThreadPool:    {fact_thread/fact_process:.2f}x FASTER")
            print(f"  ‚úÖ WINNER: ProcessPool (GIL makes threads ineffective)")

            # Calculate GIL impact
            theoretical_max = fact_new / calculator.cpu_cores
            gil_overhead = (fact_thread / theoretical_max) * 100
            print(f"\n  üìâ GIL Impact: ThreadPool is {gil_overhead:.0f}% of ideal parallel performance")

        # IO-BOUND TASKS: WEB CRAWLING
        print("\n" + "-"*70)
        print("3Ô∏è‚É£  IO-BOUND: WEB CRAWLING (15 requests to ipsantarem.pt)")
        print("-"*70)
        if results.get('web_new_threads') and results.get('web_thread_pool'):
            web_new = results['web_new_threads']['avg_time']
            web_thread = results['web_thread_pool']['avg_time']

            print(f"  New Threads:          {web_new:>8.3f}s  ({results['web_new_threads']['avg_throughput']:.2f} tasks/s)")
            print(f"  ThreadPool (96):      {web_thread:>8.3f}s  ({results['web_thread_pool']['avg_throughput']:.2f} tasks/s)")
            print(f"\n  ‚ö° ThreadPool Speedup:                   {web_new/web_thread:.2f}x FASTER")
            print(f"  ‚úÖ WINNER: ThreadPool (efficient for I/O waiting)")

            if results.get('web_optimal_size'):
                print(f"\n  üéØ Optimal Pool Size: {results['web_optimal_size']} threads")
                print(f"     (Ratio to cores: {results['web_optimal_size']/calculator.cpu_cores:.1f}x)")

                if results.get('web_pool_sizes'):
                    print(f"\n  üìà Pool Size Performance:")
                    for size, time_val in sorted(results['web_pool_sizes'].items()):
                        ratio = size / calculator.cpu_cores
                        print(f"     {size:>4} threads ({ratio:>4.1f}x cores): {time_val:.3f}s")

        # IO-BOUND TASKS: SLEEP
        print("\n" + "-"*70)
        print("4Ô∏è‚É£  IO-BOUND: SLEEP TASKS (100 tasks, 0.05s each)")
        print("-"*70)
        if results.get('sleep_new_threads') and results.get('sleep_thread_pool'):
            sleep_new = results['sleep_new_threads']['avg_time']
            sleep_thread = results['sleep_thread_pool']['avg_time']

            print(f"  New Threads:          {sleep_new:>8.3f}s  ({results['sleep_new_threads']['avg_throughput']:.2f} tasks/s)")
            print(f"  ThreadPool (192):     {sleep_thread:>8.3f}s  ({results['sleep_thread_pool']['avg_throughput']:.2f} tasks/s)")

            if sleep_thread < sleep_new:
                print(f"\n  ‚ö° ThreadPool Speedup:                   {sleep_new/sleep_thread:.2f}x FASTER")
                print(f"  ‚úÖ WINNER: ThreadPool (handles many idle threads efficiently)")
            else:
                print(f"\n  ‚ö° New Threads Speedup:                  {sleep_thread/sleep_new:.2f}x FASTER")
                print(f"  ‚ö†Ô∏è  New threads faster (tasks too light, pool overhead dominates)")

            if results.get('sleep_optimal_size'):
                print(f"\n  üéØ Optimal Pool Size: {results['sleep_optimal_size']} threads")
                print(f"     (Ratio to cores: {results['sleep_optimal_size']/calculator.cpu_cores:.1f}x)")

                if results.get('sleep_pool_sizes'):
                    print(f"\n  üìà Pool Size Performance:")
                    for size, time_val in sorted(results['sleep_pool_sizes'].items()):
                        ratio = size / calculator.cpu_cores
                        speedup = sleep_new / time_val
                        print(f"     {size:>4} threads ({ratio:>4.1f}x cores): {time_val:.3f}s  [Speedup: {speedup:.2f}x]")

        # SUMMARY TABLE
        print("\n" + "="*70)
        print("üìã SUMMARY TABLE - BEST APPROACH FOR EACH WORKLOAD")
        print("="*70)
        print(f"\n{'Workload Type':<25} {'Best Approach':<20} {'Optimal Size':<15} {'Speedup'}")
        print("-"*70)

        # Image Processing
        if results.get('img_process_pool'):
            img_speedup = results['img_new_threads']['avg_time'] / results['img_process_pool']['avg_time']
            print(f"{'CPU: Image Processing':<25} {'ProcessPool':<20} {f'{calculator.cpu_cores} processes':<15} {img_speedup:.2f}x")

        # Factorial
        if results.get('fact_process_pool'):
            fact_speedup = results['fact_new_threads']['avg_time'] / results['fact_process_pool']['avg_time']
            print(f"{'CPU: Factorial':<25} {'ProcessPool':<20} {f'{calculator.cpu_cores} processes':<15} {fact_speedup:.2f}x")

        # Web Crawling
        if results.get('web_thread_pool') and results.get('web_optimal_size'):
            web_speedup = results['web_new_threads']['avg_time'] / results['web_thread_pool']['avg_time']
            print(f"{'IO: Web Crawling':<25} {'ThreadPool':<20} {f'{results["web_optimal_size"]} threads':<15} {web_speedup:.2f}x")

        # Sleep
        if results.get('sleep_thread_pool') and results.get('sleep_optimal_size'):
            if results['sleep_thread_pool']['avg_time'] < results['sleep_new_threads']['avg_time']:
                sleep_speedup = results['sleep_new_threads']['avg_time'] / results['sleep_thread_pool']['avg_time']
                print(f"{'IO: Sleep (light)':<25} {'ThreadPool':<20} {f'{results["sleep_optimal_size"]} threads':<15} {sleep_speedup:.2f}x")

        # KEY INSIGHTS
        print("\n" + "="*70)
        print("üîç KEY FINDINGS - YOUR ACTUAL DATA")
        print("="*70)

        print("\n1Ô∏è‚É£  PYTHON'S GIL SEVERELY LIMITS CPU-BOUND THREADING:")
        if results.get('fact_thread_pool') and results.get('fact_process_pool'):
            fact_new = results['fact_new_threads']['avg_time']
            fact_thread = results['fact_thread_pool']['avg_time']
            fact_process = results['fact_process_pool']['avg_time']
            speedup = fact_thread / fact_process

            print(f"   üìå Factorial Test (50 tasks of 50,000!):")
            print(f"      ‚Ä¢ New Threads (baseline):  {fact_new:.2f}s")
            print(f"      ‚Ä¢ ThreadPool (24 threads): {fact_thread:.2f}s  [NO SPEEDUP - GIL limited!]")
            print(f"      ‚Ä¢ ProcessPool (24 cores):  {fact_process:.2f}s  [‚ö° {speedup:.2f}x FASTER!]")
            print(f"   ")
            print(f"   üí° INSIGHT: ThreadPool gives almost ZERO speedup for CPU work!")
            print(f"      The GIL prevents threads from running Python code in parallel.")
            print(f"      ProcessPool bypasses the GIL ‚Üí {speedup:.2f}x faster with 24 cores.")

        print("\n2Ô∏è‚É£  PROCESS OVERHEAD CAN DOMINATE FOR QUICK TASKS:")
        if results.get('img_new_threads') and results.get('img_process_pool'):
            img_new = results['img_new_threads']['avg_time']
            img_thread = results['img_thread_pool']['avg_time']
            img_process = results['img_process_pool']['avg_time']

            print(f"   üìå Image Processing Test (30 images, 800x600px, 14 filters):")
            print(f"      ‚Ä¢ New Threads:             {img_new:.3f}s")
            print(f"      ‚Ä¢ ThreadPool (24 threads): {img_thread:.3f}s")
            print(f"      ‚Ä¢ ProcessPool (24 cores):  {img_process:.3f}s")

            if img_process > img_thread:
                overhead = ((img_process / img_new) - 1) * 100
                print(f"   ")
                print(f"   ‚ö†Ô∏è  WARNING: ProcessPool is SLOWER here!")
                print(f"      Process spawning + pickle serialization overhead > computation time")
                print(f"      Overhead: +{overhead:.0f}% compared to threads")
                print(f"   üí° LESSON: Measure! Not all CPU tasks benefit from multiprocessing.")
            else:
                print(f"   ‚úÖ ProcessPool wins even for this task")

        print("\n3Ô∏è‚É£  OPTIMAL POOL SIZES VARY DRAMATICALLY BY WORKLOAD:")
        print(f"   üìå Your 24-core system optimal configurations:")

        if results.get('web_optimal_size'):
            web_ratio = results['web_optimal_size'] / calculator.cpu_cores
            web_new = results['web_new_threads']['avg_time']
            web_optimal_time = results['web_pool_sizes'][results['web_optimal_size']]
            web_speedup = web_new / web_optimal_time
            print(f"      ‚Ä¢ Web Crawling (network I/O):  {results['web_optimal_size']} threads ({web_ratio:.1f}x cores)")
            print(f"        Speedup vs new threads: {web_speedup:.2f}x")

        if results.get('sleep_optimal_size'):
            sleep_ratio = results['sleep_optimal_size'] / calculator.cpu_cores
            sleep_new = results['sleep_new_threads']['avg_time']
            sleep_optimal_time = results['sleep_pool_sizes'][results['sleep_optimal_size']]
            sleep_speedup = sleep_new / sleep_optimal_time
            print(f"      ‚Ä¢ Sleep tasks (light I/O):     {results['sleep_optimal_size']} threads ({sleep_ratio:.1f}x cores)")
            print(f"        Speedup vs new threads: {sleep_speedup:.2f}x")

        print(f"      ‚Ä¢ CPU-bound tasks:             {calculator.cpu_cores} processes (1x cores)")
        print(f"   ")
        print(f"   üí° RULE: More I/O waiting ‚Üí more threads can be used efficiently")

        print("\n4Ô∏è‚É£  THREAD POOLS BEAT 'NEW THREADS' FOR I/O TASKS:")
        if results.get('web_new_threads') and results.get('web_thread_pool'):
            web_new = results['web_new_threads']['avg_time']
            web_pool = results['web_thread_pool']['avg_time']
            web_improvement = ((web_new - web_pool) / web_new) * 100

            print(f"   üìå Web Crawling (15 requests to ipsantarem.pt):")
            print(f"      ‚Ä¢ New Threads:  {web_new:.2f}s")
            print(f"      ‚Ä¢ ThreadPool:   {web_pool:.2f}s  ({web_improvement:.1f}% faster)")
            print(f"   ")
            print(f"   üí° Thread reuse eliminates creation overhead!")

        print("\n5Ô∏è‚É£  TOO MANY THREADS HURTS PERFORMANCE:")
        if results.get('web_pool_sizes'):
            print(f"   üìå Web Crawling with different pool sizes:")
            sorted_sizes = sorted(results['web_pool_sizes'].items(), key=lambda x: x[1])
            best_size, best_time = sorted_sizes[0]
            worst_size, worst_time = sorted_sizes[-1]
            overhead = ((worst_time - best_time) / best_time) * 100

            for size, time in sorted(results['web_pool_sizes'].items()):
                ratio = size / calculator.cpu_cores
                marker = " ‚úÖ OPTIMAL" if size == best_size else ""
                marker = " ‚ùå TOO MANY" if size == worst_size else marker
                print(f"      ‚Ä¢ {size:>3} threads ({ratio:>4.1f}x cores): {time:.3f}s{marker}")

            print(f"   ")
            print(f"   üí° {worst_size} threads is {overhead:.0f}% SLOWER than {best_size} threads!")
            print(f"      Too many threads ‚Üí context switching overhead dominates")

        print("\n" + "="*70)
        print("üìù RECOMMENDATIONS FOR YOUR RESEARCH PAPER")
        print("="*70)
        print("\n‚úÖ USE PROCESSPOOL FOR CPU-BOUND TASKS (when task duration > 1s)")
        print("   ‚Üí Bypasses Python's GIL")
        print("   ‚Üí Set workers = CPU core count")
        if results.get('fact_process_pool'):
            print(f"   ‚Üí Your data: {fact_thread/fact_process:.1f}x speedup on 24 cores")

        print("\n‚úÖ USE THREADPOOL FOR I/O-BOUND TASKS")
        print("   ‚Üí Threads efficiently handle I/O waiting")
        print("   ‚Üí Start with 2-4x CPU cores for network I/O")
        print("   ‚Üí Can scale to 8-32x cores for very light I/O")
        if results.get('web_optimal_size'):
            print(f"   ‚Üí Your data: {results['web_optimal_size']} threads optimal for web crawling")

        print("\n‚ùå NEVER CREATE NEW THREADS PER TASK")
        print("   ‚Üí Thread creation has overhead")
        print("   ‚Üí Pool reuse is always better or equal")

        print("\n‚ö†Ô∏è  ALWAYS MEASURE YOUR SPECIFIC WORKLOAD")
        print("   ‚Üí Process overhead can dominate short tasks")
        print("   ‚Üí Optimal pool size depends on task characteristics")
        print("   ‚Üí What works for one workload may not work for another")

        print("\n" + "="*70)
        print("‚úÖ ALL TESTS COMPLETED SUCCESSFULLY")
        print("="*70)

    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Testing interrupted by user")
    except Exception as e:
        print(f"\n\n‚ùå Error during testing: {e}")
        import traceback
        traceback.print_exc()